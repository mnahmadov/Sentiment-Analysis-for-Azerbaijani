{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13ec915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b58d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "df = pd.read_excel('Sentiments.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3d9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# remove sentiments that are not labeled\n",
    "df = df[df.Sentiment.notnull()]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = df[df.Comment.notnull()]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# In our case, Percentage and Topic columns are not necessary\n",
    "# Dropping unnecessary columns\n",
    "df.drop(columns=[\"Percentage\", \"Topic\"], inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# removing comments those sentiments are undefined\n",
    "undefined_sentiment_labels = ('Undefined', 'undefined', 'Undefiend', '(?)')\n",
    "df.drop(df[df['Sentiment'].isin(undefined_sentiment_labels)].index, inplace = True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# renaming the positive sentiment labels into one label: 'Postive'\n",
    "positive_sentiment_labels = ('positive', 'Positive ', 'Postive')\n",
    "df[\"Sentiment\"] = df[\"Sentiment\"].replace(positive_sentiment_labels, 'Positive')\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# renaming the negative sentiment labels into one label: 'Negative'\n",
    "negative_sentiment_labels = (' Negative', 'Negativ e', 'negative', ' Neg')\n",
    "df[\"Sentiment\"] = df[\"Sentiment\"].replace(negative_sentiment_labels, 'Negative')\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# renaming the neutral sentiment labels into one label: 'Neutral'\n",
    "neutral_sentiment_labels = ('neutral')\n",
    "df[\"Sentiment\"] = df[\"Sentiment\"].replace(neutral_sentiment_labels, 'Neutral')\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = df.drop(df[df['Sentiment'] == 'Neutral'].sample(frac=0.33).index)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb3e27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative' 'Positive' 'Neutral']\n",
      "(21070, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df['Sentiment'].unique())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd96217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the pre-built Stemmer for Azerbaijani Language\n",
    "# Thanks for the efforts of Samir T. Mammadov\n",
    "\n",
    "# Stemmer class definition\n",
    "class Stemmer:\n",
    "    # Stores the words loaded from the words.txt file\n",
    "    words = set()\n",
    "    # Stores the suffixes loaded from the suffix.txt file\n",
    "    suffixes = []\n",
    "    # Stores all possible stems of a word\n",
    "    stems = []\n",
    "\n",
    "    # Constructor of the Stemmer class\n",
    "    def __init__(self):\n",
    "        # Loads words from the words.txt file\n",
    "        self.__load_words()\n",
    "        # Loads suffixes from the suffix.txt file\n",
    "        self.__load_suffixes()\n",
    "\n",
    "    # Destructor of the Stemmer class\n",
    "    def __del__(self):\n",
    "        # Clear both lists to free the memory space\n",
    "        self.words.clear()\n",
    "        self.suffixes.clear()\n",
    "\n",
    "    # Loads the words from the word.txt file into memory\n",
    "    def __load_words(self):\n",
    "        # Open words.txt file in read mode with utf-8 encoding.\n",
    "        with open(\"words.txt\", \"r\", encoding=\"utf8\") as words_file:\n",
    "            # Iterate over each line in the words.txt file\n",
    "            for word in words_file:\n",
    "                # Trim the spaces and newline characters from the string before adding to the list\n",
    "                self.words.add(word.strip())\n",
    "\n",
    "    # Loads the suffixes from the suffix.txt file into memory\n",
    "    def __load_suffixes(self):\n",
    "        # Open suffix.txt file in read mode with utf-8 encoding\n",
    "        with open(\"suffix.txt\", \"r\", encoding=\"utf8\") as suffix_file:\n",
    "            # Iterate over each line in the suffix.txt file\n",
    "            for suffix in suffix_file:\n",
    "                # Trim the spaces and newline characters from the string before adding to the list\n",
    "                self.suffixes.append(suffix.strip())\n",
    "\n",
    "    # Removes one suffix at a time\n",
    "    def suffix(self, word):\n",
    "        for suffix in self.suffixes:\n",
    "            # If the word ends with the particular suffix, create a new word by removing that suffix\n",
    "            if word.endswith(suffix) and (word[:word.rfind(suffix)] in self.words):\n",
    "                word = word[:word.rfind(suffix)]\n",
    "                return word\n",
    "        # Iterate over the suffixes\n",
    "        for suffix in self.suffixes:\n",
    "            # If the word ends with the particular suffix, create a new word by removing that suffix\n",
    "            if word.endswith(suffix):\n",
    "                word = word[:word.rfind(suffix)]\n",
    "                return word\n",
    "        return word\n",
    "\n",
    "    # Converts changed suffixes and roots to their original forms\n",
    "    def converter(self, word):\n",
    "        if word.endswith('lığ') or word.endswith('luğ') or word.endswith('lağ') or word.endswith('cığ'):\n",
    "            l=list(word); l[-1]='q'; return \"\".join(l)\n",
    "        if word.endswith('liy') or word.endswith('lüy'):\n",
    "            l=list(word); l[-1]='k'; return \"\".join(l)\n",
    "        if word.endswith('cağ'):\n",
    "            l=list(word); l[-1]='q'; return \"\".join(l)\n",
    "        if word.endswith('cəy'):\n",
    "            l=list(word); l[-1]='k'; return \"\".join(l)\n",
    "        if word.endswith('ığ') or word.endswith('uğ') or word.endswith('ağ'):\n",
    "            l=list(word); l[-1]='q'; return \"\".join(l)\n",
    "        if word.endswith('iy') or word.endswith('üy') or word.endswith('əy'):\n",
    "            l=list(word); l[-1]='k'; return \"\".join(l)\n",
    "        if word == 'ed':\n",
    "            l=list(word); l[1]='t'; return \"\".join(l)\n",
    "        if word == 'ged':\n",
    "            l=list(word); l[2]='t'; return \"\".join(l)\n",
    "        return word\n",
    "        \n",
    "    # Returns the stemmed version of word\n",
    "    def stem_word(self, word):\n",
    "        # Change the word to lowercase.\n",
    "        word = word.lower()\n",
    "        # Convert if the word has changed root or suffix\n",
    "        word = self.converter(word)\n",
    "        # If word is already in the list, append it to stems list\n",
    "        if word.isnumeric():\n",
    "                self.stems.append(word)\n",
    "        else: \n",
    "            if word in self.words:\n",
    "                self.stems.append(word)\n",
    "        # Iterate through suffixes\n",
    "        for suffix in self.suffixes:\n",
    "                # If word ends with current suffix, remove the suffix and stem again\n",
    "                if word.endswith(suffix):\n",
    "                    self.stem_word(word[:word.rfind(suffix)])\n",
    "                \n",
    "    # Returns the stemmed versions of the given words\n",
    "    def stem_words(self, list_of_words):\n",
    "        # Iterate over the range of word indexes\n",
    "        list_of_stems = []\n",
    "        for word in list_of_words:\n",
    "            # Empty the stems list for each word\n",
    "            self.stems = []\n",
    "            # Apply stemming to each word in the list.\n",
    "            self.stem_word(word)\n",
    "            selected_stem = \"\"\n",
    "            # Choose the stem with the maximum length\n",
    "            for stem in self.stems:\n",
    "                if len(stem) > len(selected_stem): selected_stem = stem\n",
    "            # If there is no selected stem for word, append the word itself\n",
    "            if selected_stem == \"\":\n",
    "                selected_stem = word\n",
    "            # Append the stem of the current word to the list of stems\n",
    "            list_of_stems.append(selected_stem)\n",
    "            \n",
    "        # Return the updated list.\n",
    "        return list_of_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d4307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing continues\n",
    "\n",
    "def remove_punctuation(comment):\n",
    "    # a function to remove punctuations from the given comment\n",
    "    \n",
    "    punctuations = string.punctuation\n",
    "    for punctuation in punctuations:\n",
    "        if punctuation in comment:\n",
    "            comment = comment.replace(punctuation, '')\n",
    "    comment = comment.replace('-', '')\n",
    "    return comment\n",
    "\n",
    "\n",
    "stemmer = Stemmer()\n",
    "for i in range(df.shape[0]):\n",
    "    if not isinstance(df.at[i, 'Comment'], str): # check if the comment is a type string\n",
    "        df.at[i, 'Comment'] = str(df.at[i, 'Comment'])\n",
    "    \n",
    "    original_comment = df.at[i, 'Comment']\n",
    "    comment = original_comment.lower() # lowercasing the comment\n",
    "    comment = remove_punctuation(comment) # removing punctuations from it\n",
    "    comment = \" \".join(stemmer.stem_words(comment.split())) # stemming the words in it\n",
    "    df.at[i, 'Comment'] = comment # replacing original comment with preprocessed comment \n",
    "    \n",
    "    # print(\"Preprocessed Comment:\", df.at[i, 'Comment'])\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e33512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts().plot.bar(color = 'red', figsize = (6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5460cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Comment'], df['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bde8c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb156cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using X_train and y_train, we create the vocabulary\n",
    "\n",
    "n = len(X_train) # number_of_sentiments\n",
    "\n",
    "# vocabulary:\n",
    "# keys are words, \n",
    "# values are a set that contains three elements that are \n",
    "# how many times the word appears in positive, negative, and neutral comments\n",
    "vocabulary = {}\n",
    "\n",
    "for i in range(n):\n",
    "    comment = X_train[i]\n",
    "    sentiment = y_train[i]\n",
    "    \n",
    "    if not isinstance(comment, str): # check if the comment is a type string\n",
    "        comment = str(comment)\n",
    "        \n",
    "    for word in comment.split():\n",
    "        # if word has not been previously seen, add it to the vocabulary with initial value\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = [0, 0, 0]\n",
    "        \n",
    "        # based on the sentiment value, modify the value of the word key\n",
    "        if sentiment == 'Positive':\n",
    "            vocabulary[word][0] += 1\n",
    "        elif sentiment == 'Negative':\n",
    "            vocabulary[word][1] += 1\n",
    "        else:\n",
    "            vocabulary[word][2] += 1\n",
    "        \n",
    "# print(vocabulary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b7155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(comment):\n",
    "    total_positives, total_negatives, total_neutrals = 0, 0, 0\n",
    "    for word in comment:\n",
    "        if word not in vocabulary:\n",
    "            continue\n",
    "        total_positives += vocabulary[word][0]\n",
    "        total_negatives += vocabulary[word][1]\n",
    "        total_neutrals += vocabulary[word][2]\n",
    "    return np.array([1, total_positives, total_negatives, total_neutrals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "598c6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_own = np.zeros((X_train.shape[0], 4)) # initializing X\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_own[i, :] = extract_features(X_train[i])\n",
    "#     print(X[i, :])\n",
    "\n",
    "X_test_own = np.zeros((X_test.shape[0], 4)) # initializing X_test\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_own[i, :] = extract_features(X_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd189156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "# x: (sum of the positive frequencies of the words of the comment)\n",
    "# y: (sum of the negative frequencies of the words of the comment)\n",
    "# z: (sum of the neutral frequencies of the words of the comment)\n",
    "\n",
    "X_scatter = pd.DataFrame(X_own[:, 1:], columns=['x', 'y', 'z'])\n",
    "X_scatter['Sentiment'] = y_train\n",
    "fig = px.scatter_3d(X_scatter, x='x', y='y', z='z', color='Sentiment')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a027132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training using the feature extaction (implemented from scratch) \n",
      "\n",
      "(a) Logistic Regression Classifier \n",
      "\n",
      "Accuracy: 0.40389178927384906\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.43      0.13      0.20      1285\n",
      "     Neutral       0.40      0.86      0.54      1617\n",
      "    Positive       0.45      0.11      0.18      1312\n",
      "\n",
      "    accuracy                           0.40      4214\n",
      "   macro avg       0.42      0.37      0.31      4214\n",
      "weighted avg       0.42      0.40      0.32      4214\n",
      " \n",
      "\n",
      "(b) Multionmial Naive Bayes Classifier \n",
      "\n",
      "Accuracy: 0.37019458946369244\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.35      0.40      0.37      1285\n",
      "     Neutral       0.41      0.28      0.33      1617\n",
      "    Positive       0.36      0.45      0.40      1312\n",
      "\n",
      "    accuracy                           0.37      4214\n",
      "   macro avg       0.37      0.38      0.37      4214\n",
      "weighted avg       0.38      0.37      0.37      4214\n",
      " \n",
      "\n",
      "(c) Decision Tree Classifier \n",
      "\n",
      "Accuracy: 0.35975320360702423\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.32      0.34      0.33      1285\n",
      "     Neutral       0.39      0.40      0.39      1617\n",
      "    Positive       0.36      0.34      0.35      1312\n",
      "\n",
      "    accuracy                           0.36      4214\n",
      "   macro avg       0.36      0.36      0.36      4214\n",
      "weighted avg       0.36      0.36      0.36      4214\n",
      " \n",
      "\n",
      "(d) Random Forest Classifier \n",
      "\n",
      "Accuracy: 0.38134788799240626\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.34      0.35      0.34      1285\n",
      "     Neutral       0.40      0.46      0.43      1617\n",
      "    Positive       0.39      0.31      0.35      1312\n",
      "\n",
      "    accuracy                           0.38      4214\n",
      "   macro avg       0.38      0.37      0.37      4214\n",
      "weighted avg       0.38      0.38      0.38      4214\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "print(\"Model Training using the feature extaction (implemented from scratch)\", \"\\n\")\n",
    "\n",
    "LRC = LogisticRegression(random_state=0, max_iter=200)\n",
    "LRC.fit(X_own, y_train)\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(X_own, y_train)\n",
    "\n",
    "# XGBC = XGBClassifier()\n",
    "# y_train_xgb = encoder.fit_transform(y_train)\n",
    "# y_test_xgb = encoder.fit_transform(y_test)\n",
    "# XGBC.fit(X_own, y_train_xgb)\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_own, y_train)\n",
    "\n",
    "MNBC = MultinomialNB(force_alpha=True)\n",
    "MNBC.fit(X_own, y_train)\n",
    "\n",
    "y_predicted_LRC = np.empty((y_test.shape[0], 1), dtype=object)\n",
    "y_predicted_DTC = np.empty((y_test.shape[0], 1), dtype=object)\n",
    "# y_predicted_XGBC = np.empty((y_test.shape[0], ), dtype=object)\n",
    "y_predicted_RFC = np.empty((y_test.shape[0], 1), dtype=object)\n",
    "y_predicted_MNBC = np.empty((y_test.shape[0], 1), dtype=object)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    y_predicted_LRC[i] = LRC.predict(X_test_own[i].reshape(1, -1))[0]\n",
    "    y_predicted_DTC[i] = DTC.predict(X_test_own[i].reshape(1, -1))[0]\n",
    "    # y_predicted_XGBC[i] = XGBC.predict(X_test_own[i].reshape(1, -1))[0]\n",
    "    y_predicted_RFC[i] = RFC.predict(X_test_own[i].reshape(1, -1))[0]\n",
    "    y_predicted_MNBC[i] = MNBC.predict(X_test_own[i].reshape(1, -1))[0]\n",
    "\n",
    "print(\"(a) Logistic Regression Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predicted_LRC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test, y_predicted_LRC), \"\\n\")\n",
    "\n",
    "\n",
    "print(\"(b) Multionmial Naive Bayes Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predicted_MNBC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test, y_predicted_MNBC), \"\\n\")\n",
    "\n",
    "\n",
    "print(\"(c) Decision Tree Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_predicted_DTC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test, y_predicted_DTC), \"\\n\")\n",
    "\n",
    "# print(\"XGBoost Classifier\")\n",
    "# print(accuracy_score(y_test_xgb, y_predicted_XGBC))\n",
    "# print(classification_report(y_test_xgb, y_predicted_XGBC))\n",
    "\n",
    "print(\"(d) Random Forest Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predicted_RFC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test, y_predicted_RFC), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9538c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training using CountVectrozier for feature extraction \n",
      "\n",
      "(a) Logistic Regression Classifier \n",
      "\n",
      "Accuracy: 0.5775984812529663\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.57      0.50      0.54      1285\n",
      "     Neutral       0.53      0.64      0.58      1617\n",
      "    Positive       0.65      0.57      0.61      1312\n",
      "\n",
      "    accuracy                           0.58      4214\n",
      "   macro avg       0.59      0.57      0.58      4214\n",
      "weighted avg       0.58      0.58      0.58      4214\n",
      " \n",
      "\n",
      "(b) Multinomial Naive Bayes Classifier \n",
      "\n",
      "Accuracy: 0.5700047460844803\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.53      0.58      0.55      1285\n",
      "     Neutral       0.55      0.55      0.55      1617\n",
      "    Positive       0.65      0.59      0.62      1312\n",
      "\n",
      "    accuracy                           0.57      4214\n",
      "   macro avg       0.58      0.57      0.57      4214\n",
      "weighted avg       0.57      0.57      0.57      4214\n",
      " \n",
      "\n",
      "(c) Decision Tree Classifier \n",
      "\n",
      "Accuracy: 0.49905078310393924\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.45      0.42      0.44      1285\n",
      "     Neutral       0.49      0.50      0.50      1617\n",
      "    Positive       0.55      0.57      0.56      1312\n",
      "\n",
      "    accuracy                           0.50      4214\n",
      "   macro avg       0.50      0.50      0.50      4214\n",
      "weighted avg       0.50      0.50      0.50      4214\n",
      " \n",
      "\n",
      "(d) XGBoost Classifier \n",
      "\n",
      "Accuracy: 0.5434266729947793\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.38      0.45      1285\n",
      "           1       0.48      0.76      0.59      1617\n",
      "           2       0.72      0.44      0.55      1312\n",
      "\n",
      "    accuracy                           0.54      4214\n",
      "   macro avg       0.59      0.53      0.53      4214\n",
      "weighted avg       0.58      0.54      0.53      4214\n",
      " \n",
      "\n",
      "(e) Random Forest Classifier \n",
      "\n",
      "Accuracy: 0.5431893687707641\n",
      "Calssification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.54      0.37      0.44      1285\n",
      "     Neutral       0.51      0.61      0.55      1617\n",
      "    Positive       0.59      0.63      0.61      1312\n",
      "\n",
      "    accuracy                           0.54      4214\n",
      "   macro avg       0.55      0.54      0.54      4214\n",
      "weighted avg       0.54      0.54      0.54      4214\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "print(\"Model Training using CountVectrozier for feature extraction\", \"\\n\")\n",
    "corpus = []\n",
    "for comment in df['Comment']:\n",
    "    corpus.append(str(comment))\n",
    "\n",
    "document_term = vectorizer.fit_transform(corpus)\n",
    "\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(document_term, df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "LRC = LogisticRegression(random_state=0, max_iter=250)\n",
    "LRC.fit(X_train_cv, y_train_cv)\n",
    "y_predicted_LRC = LRC.predict(X_test_cv)\n",
    "\n",
    "print(\"(a) Logistic Regression Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test_cv, y_predicted_LRC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test_cv, y_predicted_LRC), \"\\n\")\n",
    "\n",
    "\n",
    "MNBC = MultinomialNB(force_alpha=True)\n",
    "MNBC.fit(X_train_cv, y_train_cv)\n",
    "y_predicted_MNBC = MNBC.predict(X_test_cv)\n",
    "\n",
    "print(\"(b) Multinomial Naive Bayes Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test_cv, y_predicted_MNBC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test_cv, y_predicted_MNBC), \"\\n\")\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(X_train_cv, y_train_cv)\n",
    "y_predicted_DTC = DTC.predict(X_test_cv)\n",
    "\n",
    "print(\"(c) Decision Tree Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test_cv, y_predicted_DTC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test_cv, y_predicted_DTC), \"\\n\")\n",
    "\n",
    "\n",
    "XGBC = XGBClassifier()\n",
    "\n",
    "y_train_cv_xgb = encoder.fit_transform(y_train_cv)\n",
    "y_test_cv_xgb = encoder.fit_transform(y_test_cv)\n",
    "\n",
    "XGBC.fit(X_train_cv, y_train_cv_xgb)\n",
    "\n",
    "# make predictions on the test data and evaluate the model\n",
    "y_predicted_XGBC = XGBC.predict(X_test_cv)\n",
    "\n",
    "print(\"(d) XGBoost Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test_cv_xgb, y_predicted_XGBC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test_cv_xgb, y_predicted_XGBC), \"\\n\")\n",
    "\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "y_predicted_RFC = RFC.predict(X_test_cv)\n",
    "\n",
    "print(\"(e) Random Forest Classifier\", \"\\n\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test_cv, y_predicted_RFC))\n",
    "print(\"Calssification Report:\", \"\\n\", classification_report(y_test_cv, y_predicted_RFC), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfc63e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Positive\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Bu gün yeni öyrənmə səyahətinə başlamaq üçün əla gündür.\"\n",
    "\n",
    "# Transform the the sentence\n",
    "new_document_term = vectorizer.transform([test_sentence])\n",
    "\n",
    "predicted_label = LRC.predict(new_document_term)\n",
    "\n",
    "print(\"Predicted label:\", predicted_label[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
